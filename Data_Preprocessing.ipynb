{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive to enable access to any directory on Drive inside the Colab notebook.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Setting up PySpark in Colab, designate where the installer should be located\n",
        "%cd /content/drive/MyDrive/Big_Data"
      ],
      "metadata": {
        "id": "3jqfJf0Jay-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e588c250-0b7c-4f60-b64e-4e5e53840149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Big_Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "#Spark Installer \n",
        "!wget -v https://dlcdn.apache.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop3.2.tgz "
      ],
      "metadata": {
        "id": "0n8qb1y1azE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f1856c-d907-48f7-d77b-59fb018e5b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-27 22:37:28--  https://dlcdn.apache.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop3.2.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231842529 (221M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.1.3-bin-hadoop3.2.tgz.1’\n",
            "\n",
            "spark-3.1.3-bin-had 100%[===================>] 221.10M  38.3MB/s    in 5.6s    \n",
            "\n",
            "2022-11-27 22:37:36 (39.7 MB/s) - ‘spark-3.1.3-bin-hadoop3.2.tgz.1’ saved [231842529/231842529]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Untar the Spark installer\n",
        "!tar -xvf spark-3.1.3-bin-hadoop3.2.tgz\n",
        "\n",
        "#Install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "#Set environment variables - Java and Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/drive/MyDrive/Big_Data/spark-3.1.3-bin-hadoop3.2\"\n",
        "\n",
        "#Create local Spark session\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "zxx44DB5azHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d8f0cc-87df-462e-a77c-da91836e4958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.1.3-bin-hadoop3.2/\n",
            "spark-3.1.3-bin-hadoop3.2/bin/\n",
            "spark-3.1.3-bin-hadoop3.2/bin/pyspark.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-submit\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-submit.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-class2.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-shell2.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/pyspark2.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/docker-image-tool.sh\n",
            "spark-3.1.3-bin-hadoop3.2/bin/run-example.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-submit2.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/beeline.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/beeline\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-shell\n",
            "spark-3.1.3-bin-hadoop3.2/bin/find-spark-home\n",
            "spark-3.1.3-bin-hadoop3.2/bin/sparkR2.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/find-spark-home.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/sparkR\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-class\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-sql2.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/load-spark-env.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/run-example\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-sql\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-class.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-sql.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/spark-shell.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/sparkR.cmd\n",
            "spark-3.1.3-bin-hadoop3.2/bin/load-spark-env.sh\n",
            "spark-3.1.3-bin-hadoop3.2/bin/pyspark\n",
            "spark-3.1.3-bin-hadoop3.2/README.md\n",
            "spark-3.1.3-bin-hadoop3.2/R/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/tests/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/R/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/INDEX\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/worker/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/help/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/html/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/html/R.css\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/profile/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/doc/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/doc/index.html\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.1.3-bin-hadoop3.2/R/lib/sparkr.zip\n",
            "spark-3.1.3-bin-hadoop3.2/NOTICE\n",
            "spark-3.1.3-bin-hadoop3.2/data/\n",
            "spark-3.1.3-bin-hadoop3.2/data/graphx/\n",
            "spark-3.1.3-bin-hadoop3.2/data/graphx/followers.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/graphx/users.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/license.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/kittens/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/images/license.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/ridge-data/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/kmeans_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/als/\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/als/test.data\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/pagerank_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/gmm_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/pic_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n",
            "spark-3.1.3-bin-hadoop3.2/data/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/data/streaming/AFINN-111.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-respond.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jline.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-join.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-janino.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-scala.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-javassist.html\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.1.3-bin-hadoop3.2/licenses/LICENSE-spire.txt\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/python_executable_check.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/decommissioning.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/tests/autoscale.py\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.1.3-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.1.3-bin-hadoop3.2/examples/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/dir1/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/employees.json\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/people.txt\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/users.avro\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/people.json\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/user.avsc\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/users.parquet\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/people.csv\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/users.orc\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scripts/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/pagerank.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sort.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/kmeans.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/als.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/pi.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/dataframe.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/als.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n",
            "spark-3.1.3-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-OYTr5aawQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "876167e9-4e8e-48db-d3e1-706b9f920cd9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8786c41c2f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonotonically_increasing_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munix_timestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Big_Data/spark-3.1.3-bin-hadoop3.2/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
            "\u001b[0;32m/content/drive/MyDrive/Big_Data/spark-3.1.3-bin-hadoop3.2/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 347\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-4-8786c41c2f00>:9 "
          ]
        }
      ],
      "source": [
        "import pyspark as spark\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.functions import col,udf,monotonically_increasing_id,unix_timestamp,round,avg\n",
        "import re\n",
        "sc = spark.SparkContext()\n",
        "sql = spark.SQLContext(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPG7vu15awQD"
      },
      "source": [
        "## Loading tweets dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfGen91VawQD"
      },
      "outputs": [],
      "source": [
        "# Read the json twitter data\n",
        "\n",
        "Twdf1=pd.read_json('/content/drive/MyDrive/Big_Data/doge_tweets_aug2021.json',lines = True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get only the content and date columns from the twitter dataset\n",
        "TwDF = Twdf1\n",
        "TwDF = TwDF.filter(['date', 'content'], axis=1)\n",
        "\n",
        "TwDF['date'] = pd.to_datetime(TwDF['date'])\n",
        "TwDF['date'] = TwDF['date'].dt.floor('h')\n",
        "TwDF"
      ],
      "metadata": {
        "id": "iwMXQKMkqOQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2c0ba90d-9313-4efa-a977-620d495a7cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           date  \\\n",
              "0     2021-08-01 23:00:00+00:00   \n",
              "1     2021-08-01 23:00:00+00:00   \n",
              "2     2021-08-01 23:00:00+00:00   \n",
              "3     2021-08-01 23:00:00+00:00   \n",
              "4     2021-08-01 23:00:00+00:00   \n",
              "...                         ...   \n",
              "76961 2021-08-07 00:00:00+00:00   \n",
              "76962 2021-08-07 00:00:00+00:00   \n",
              "76963 2021-08-07 00:00:00+00:00   \n",
              "76964 2021-08-07 00:00:00+00:00   \n",
              "76965 2021-08-07 00:00:00+00:00   \n",
              "\n",
              "                                                 content  \n",
              "0      The current value of 1 DOGE in USD is: $0.2045...  \n",
              "1      Burger King Starts Accepting Dogecoin in Brazi...  \n",
              "2      $DOGE #Dogecoin has been moving up since I sai...  \n",
              "3      50% Off!\\n\\nOlympia USA Hopkins 18 in. Navy Ba...  \n",
              "4      @Tokyo_Doge @FabriLemus7 @dogecoin @elonmusk L...  \n",
              "...                                                  ...  \n",
              "76961  @BabyDogeCoin @elonmusk @MARCIANOPHONE @Alex_H...  \n",
              "76962  Bitcoin Price (USD): 42846.08 \\nEthereum Price...  \n",
              "76963  🚨BREAKING-NEWS🚨\\n\\n🗞️ Binance US CEO Steps Dow...  \n",
              "76964  The current price of one Baby Doge Coin is: $0...  \n",
              "76965  The current Doge coin price is: $0.2047 #DogeCoin  \n",
              "\n",
              "[76966 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ffd3b89-66bc-42dd-9e32-6f04a142d3d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-08-01 23:00:00+00:00</td>\n",
              "      <td>The current value of 1 DOGE in USD is: $0.2045...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-08-01 23:00:00+00:00</td>\n",
              "      <td>Burger King Starts Accepting Dogecoin in Brazi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-08-01 23:00:00+00:00</td>\n",
              "      <td>$DOGE #Dogecoin has been moving up since I sai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-08-01 23:00:00+00:00</td>\n",
              "      <td>50% Off!\\n\\nOlympia USA Hopkins 18 in. Navy Ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-08-01 23:00:00+00:00</td>\n",
              "      <td>@Tokyo_Doge @FabriLemus7 @dogecoin @elonmusk L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76961</th>\n",
              "      <td>2021-08-07 00:00:00+00:00</td>\n",
              "      <td>@BabyDogeCoin @elonmusk @MARCIANOPHONE @Alex_H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76962</th>\n",
              "      <td>2021-08-07 00:00:00+00:00</td>\n",
              "      <td>Bitcoin Price (USD): 42846.08 \\nEthereum Price...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76963</th>\n",
              "      <td>2021-08-07 00:00:00+00:00</td>\n",
              "      <td>🚨BREAKING-NEWS🚨\\n\\n🗞️ Binance US CEO Steps Dow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76964</th>\n",
              "      <td>2021-08-07 00:00:00+00:00</td>\n",
              "      <td>The current price of one Baby Doge Coin is: $0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76965</th>\n",
              "      <td>2021-08-07 00:00:00+00:00</td>\n",
              "      <td>The current Doge coin price is: $0.2047 #DogeCoin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76966 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ffd3b89-66bc-42dd-9e32-6f04a142d3d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ffd3b89-66bc-42dd-9e32-6f04a142d3d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ffd3b89-66bc-42dd-9e32-6f04a142d3d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icTrLgzhawQF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6011bce3-3f64-4c81-ad12-b462e00594bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      0        5\n",
              "1   2021-08-31 23:00:00  0.27878\n",
              "2   2021-08-31 22:00:00  0.27633\n",
              "3   2021-08-31 21:00:00  0.27703\n",
              "4   2021-08-31 20:00:00  0.27708\n",
              "5   2021-08-31 19:00:00   0.2792\n",
              "..                  ...      ...\n",
              "740 2021-08-01 04:00:00   0.2143\n",
              "741 2021-08-01 03:00:00  0.21671\n",
              "742 2021-08-01 02:00:00  0.21305\n",
              "743 2021-08-01 01:00:00  0.21045\n",
              "744 2021-08-01 00:00:00  0.21186\n",
              "\n",
              "[744 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-125ce70f-b8bd-4ede-a4f7-2a8dc8c7657a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-08-31 23:00:00</td>\n",
              "      <td>0.27878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-08-31 22:00:00</td>\n",
              "      <td>0.27633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-08-31 21:00:00</td>\n",
              "      <td>0.27703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-08-31 20:00:00</td>\n",
              "      <td>0.27708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-08-31 19:00:00</td>\n",
              "      <td>0.2792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>2021-08-01 04:00:00</td>\n",
              "      <td>0.2143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>2021-08-01 03:00:00</td>\n",
              "      <td>0.21671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>2021-08-01 02:00:00</td>\n",
              "      <td>0.21305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>2021-08-01 01:00:00</td>\n",
              "      <td>0.21045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>2021-08-01 00:00:00</td>\n",
              "      <td>0.21186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>744 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-125ce70f-b8bd-4ede-a4f7-2a8dc8c7657a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-125ce70f-b8bd-4ede-a4f7-2a8dc8c7657a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-125ce70f-b8bd-4ede-a4f7-2a8dc8c7657a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#Load the ethereum data and filter out only the date and close columns\n",
        "ETHDF=pd.read_csv('/content/drive/MyDrive/Big_Data/DogeVsUsd_Aug2021.csv',error_bad_lines=False,engine = 'python', header = None, parse_dates=True) \n",
        "\n",
        "ETHDF = ETHDF.filter([0, 5])\n",
        "ETHDF = ETHDF[1:]\n",
        "ETHDF[0] = pd.to_datetime(ETHDF[0])\n",
        "ETHDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sql dataframe\n",
        "FullDataTw=sql.createDataFrame(TwDF.astype(str))\n",
        "FullDataEth=sql.createDataFrame(ETHDF) #creating pandas df and then changing it to pyspark df"
      ],
      "metadata": {
        "id": "o-pUGE-hndCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCCljpe4awQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7778c2ad-5c87-4794-fdd1-fefccaac49bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(0=datetime.datetime(2021, 8, 31, 23, 0), 5='0.27878'),\n",
              " Row(0=datetime.datetime(2021, 8, 31, 22, 0), 5='0.27633'),\n",
              " Row(0=datetime.datetime(2021, 8, 31, 21, 0), 5='0.27703'),\n",
              " Row(0=datetime.datetime(2021, 8, 31, 20, 0), 5='0.27708'),\n",
              " Row(0=datetime.datetime(2021, 8, 31, 19, 0), 5='0.2792')]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "FullDataTw = FullDataTw.dropna() #getting rid of full empty rows\n",
        "FullDataEth.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQKia5DnawQF"
      },
      "outputs": [],
      "source": [
        "FullDataTw.select(monotonically_increasing_id().alias(\"rowId\"),\"*\")\n",
        "FullDataTw = FullDataTw.withColumnRenamed('date', 'DateTime') #setting column names of Twitter dataset\n",
        "FullDataTw = FullDataTw.withColumnRenamed('content', 'Tweet')\n",
        "FullDataEth = FullDataEth.withColumnRenamed('0', 'DateTime') #setting column names of Ethereum price dataset\n",
        "FullDataEth = FullDataEth.withColumnRenamed('5', 'Price')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FullDataTw.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqZXRhGElkrC",
        "outputId": "1abd4e6c-643d-48b5-f2c2-66213c00b7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DateTime='2021-08-01 23:00:00+00:00', Tweet='The current value of 1 DOGE in USD is: $0.20455 (📉 down 0.008550 so far today). #dogecoin'),\n",
              " Row(DateTime='2021-08-01 23:00:00+00:00', Tweet='Burger King Starts Accepting Dogecoin in Brazil — but Only for Dog\\xa0Treats https://t.co/IjkgmYjsHB'),\n",
              " Row(DateTime='2021-08-01 23:00:00+00:00', Tweet='$DOGE #Dogecoin has been moving up since I said it started being bullish and everyone laughed at me lol. https://t.co/579X7Awjg1'),\n",
              " Row(DateTime='2021-08-01 23:00:00+00:00', Tweet='50% Off!\\n\\nOlympia USA Hopkins 18 in. Navy Backpack, Blue\\n\\nhttps://t.co/Ty8T58eLlU\\n\\n#BwcDeals #Dogecoin #clearthelists #dailydeals  #DealsAndSteals https://t.co/3IjiDnhiXq'),\n",
              " Row(DateTime='2021-08-01 23:00:00+00:00', Tweet='@Tokyo_Doge @FabriLemus7 @dogecoin @elonmusk Lezgooow #tokyodoge #teamtokyodoge')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FullDataEth.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnGWFFdtmAmo",
        "outputId": "9853a730-00cd-4415-bef7-08a870180b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DateTime=datetime.datetime(2021, 8, 31, 23, 0), Price='0.27878'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 22, 0), Price='0.27633'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 21, 0), Price='0.27703'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 20, 0), Price='0.27708'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 19, 0), Price='0.2792')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FullDataEth.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TLZqEGxmAqt",
        "outputId": "fc2357c7-673a-4606-8804-4ee23f9cbeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+\n",
            "|           DateTime|  Price|\n",
            "+-------------------+-------+\n",
            "|2021-08-31 23:00:00|0.27878|\n",
            "|2021-08-31 22:00:00|0.27633|\n",
            "|2021-08-31 21:00:00|0.27703|\n",
            "|2021-08-31 20:00:00|0.27708|\n",
            "|2021-08-31 19:00:00| 0.2792|\n",
            "|2021-08-31 18:00:00| 0.2792|\n",
            "|2021-08-31 17:00:00|0.27747|\n",
            "|2021-08-31 16:00:00| 0.2801|\n",
            "|2021-08-31 15:00:00|0.27868|\n",
            "|2021-08-31 14:00:00|0.27543|\n",
            "|2021-08-31 13:00:00|0.27964|\n",
            "|2021-08-31 12:00:00|0.27727|\n",
            "|2021-08-31 11:00:00|0.27915|\n",
            "|2021-08-31 10:00:00|0.27551|\n",
            "|2021-08-31 09:00:00|0.27498|\n",
            "|2021-08-31 08:00:00| 0.2759|\n",
            "|2021-08-31 07:00:00|0.27627|\n",
            "|2021-08-31 06:00:00|0.27103|\n",
            "|2021-08-31 05:00:00|0.27327|\n",
            "|2021-08-31 04:00:00|0.27354|\n",
            "+-------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFADLI7awQG"
      },
      "source": [
        "## Pre-Processing Twitter dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grZybN6_awQG"
      },
      "outputs": [],
      "source": [
        "Tw_samp = FullDataTw  #copy of data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tweet-preprocessor"
      ],
      "metadata": {
        "id": "F8B_Ox2Ii6jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noMymHgxawQG",
        "outputId": "3cdc6c21-ded4-422f-c290-a84743105b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|            DateTime|               Tweet|       CleanedTweets|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|2021-08-01 23:00:...|The current value...|The current value...|\n",
            "|2021-08-01 23:00:...|Burger King Start...|Burger King Start...|\n",
            "|2021-08-01 23:00:...|$DOGE #Dogecoin h...|DOGE Dogecoin has...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import preprocessor as p #cleaning each tweet using tweet-preprocessor like removing hashtags,urls,emojis....\n",
        "def function_udf(input_str):\n",
        "    input_str = re.sub(r'RT', '', input_str)\n",
        "    p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION)\n",
        "    input_str = p.clean(input_str)\n",
        "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", input_str).split())\n",
        "func_udf = udf(function_udf, StringType())\n",
        "CleanDF = Tw_samp.withColumn('CleanedTweets', func_udf(Tw_samp['Tweet']))\n",
        "CleanDF.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "tbx7Tx_TjVcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a06ed1-cee2-4b4c-cc8b-71673e2889b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ooUOWRawQH"
      },
      "source": [
        "## Sentiment analysis using Vader packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNNWmDk6awQH",
        "outputId": "e6d4d227-a25a-4dd5-c33f-326f74d62a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-----+-----+-----+------+\n",
            "|            DateTime|               Tweet|       CleanedTweets|p_neg|p_neu|p_pos|p_comp|\n",
            "+--------------------+--------------------+--------------------+-----+-----+-----+------+\n",
            "|2021-08-01 23:00:...|The current value...|The current value...|  0.0|0.876|0.124|  0.34|\n",
            "|2021-08-01 23:00:...|Burger King Start...|Burger King Start...|  0.0|0.847|0.153|0.2023|\n",
            "|2021-08-01 23:00:...|$DOGE #Dogecoin h...|DOGE Dogecoin has...|  0.0|0.746|0.254|0.7003|\n",
            "+--------------------+--------------------+--------------------+-----+-----+-----+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer # using vader sentiment to generate the sentiment analysis on twitter tweets\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "def senti_score_udf(sentence):\n",
        "    snt = analyser.polarity_scores(sentence)\n",
        "    return ([snt['neg'], snt['neu'], snt['pos'], snt['compound']])\n",
        "func_udf2 = udf(senti_score_udf, ArrayType(FloatType()))\n",
        "CleanDF = CleanDF.withColumn('p_neg', func_udf2(CleanDF['CleanedTweets'])[0])\n",
        "CleanDF = CleanDF.withColumn('p_neu', func_udf2(CleanDF['CleanedTweets'])[1])\n",
        "CleanDF = CleanDF.withColumn('p_pos', func_udf2(CleanDF['CleanedTweets'])[2])\n",
        "CleanDF = CleanDF.withColumn('p_comp', func_udf2(CleanDF['CleanedTweets'])[3])\n",
        "CleanDF.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mciSWpCLawQI",
        "outputId": "78905e75-7d00-424a-d3bc-7ac1bf250cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+--------------------+-----+-----+-----+------+\n",
            "|           DateTime|               Tweet|       CleanedTweets|p_neg|p_neu|p_pos|p_comp|\n",
            "+-------------------+--------------------+--------------------+-----+-----+-----+------+\n",
            "|2021-08-01 23:00:00|The current value...|The current value...|  0.0|0.876|0.124|  0.34|\n",
            "|2021-08-01 23:00:00|Burger King Start...|Burger King Start...|  0.0|0.847|0.153|0.2023|\n",
            "|2021-08-01 23:00:00|$DOGE #Dogecoin h...|DOGE Dogecoin has...|  0.0|0.746|0.254|0.7003|\n",
            "+-------------------+--------------------+--------------------+-----+-----+-----+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#changing datatype\n",
        "CleanDF = CleanDF.withColumn(\"DateTime\",CleanDF['DateTime'].cast(TimestampType()))\n",
        "CleanDF.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFUnedd8awQI",
        "outputId": "4a682e02-cca1-472a-a764-23ec281147d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+-----+-----+-----+------+\n",
            "|          Date_Time|      Cleaned_Tweets|p_neg|p_neu|p_pos|p_comp|\n",
            "+-------------------+--------------------+-----+-----+-----+------+\n",
            "|2021-08-01 23:00:00|The current value...|  0.0|0.876|0.124|  0.34|\n",
            "|2021-08-01 23:00:00|Burger King Start...|  0.0|0.847|0.153|0.2023|\n",
            "|2021-08-01 23:00:00|DOGE Dogecoin has...|  0.0|0.746|0.254|0.7003|\n",
            "|2021-08-01 23:00:00|50 Off Olympia US...|  0.0|  1.0|  0.0|   0.0|\n",
            "|2021-08-01 23:00:00|Lezgooow tokyodog...|  0.0|  1.0|  0.0|   0.0|\n",
            "+-------------------+--------------------+-----+-----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw = CleanDF.selectExpr(\"DateTime as Date_Time\", \"CleanedTweets as Cleaned_Tweets\", \"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "FinalTw.show(5) #selecting necessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-8mJEAuawQJ"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime \n",
        "from dateutil import parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J4IIOoFawQJ",
        "outputId": "29513d13-6f19-472b-9c62-309f1b50cf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+\n",
            "|           DateTime|  Price|\n",
            "+-------------------+-------+\n",
            "|2021-08-31 23:00:00|0.27878|\n",
            "|2021-08-31 22:00:00|0.27633|\n",
            "|2021-08-31 21:00:00|0.27703|\n",
            "|2021-08-31 20:00:00|0.27708|\n",
            "|2021-08-31 19:00:00| 0.2792|\n",
            "+-------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "FinalEth = FullDataEth\n",
        "FinalEth.show(5)#In this cell, casting to timesstamp, changing col names and casting price type to double"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieuL-ZWpawQK"
      },
      "source": [
        "## Dataframes Look like this..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMSBC_bWawQK",
        "outputId": "54ef2f95-71f8-43c6-f637-84b681bb3340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date_Time: timestamp (nullable = true)\n",
            " |-- Cleaned_Tweets: string (nullable = true)\n",
            " |-- p_neg: float (nullable = true)\n",
            " |-- p_neu: float (nullable = true)\n",
            " |-- p_pos: float (nullable = true)\n",
            " |-- p_comp: float (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNTRhyZdawQK",
        "outputId": "29b942fb-3fcb-4497-a3e2-a6531c150873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DateTime: timestamp (nullable = true)\n",
            " |-- Price: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "744"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "FinalEth.printSchema()\n",
        "FinalEth.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y06qrGUawQL"
      },
      "source": [
        "## Truncating timestamps to hours and then grouping them by hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-2WkhGdawQL",
        "outputId": "d39c6ba6-02c9-4495-b3fb-75ae9354c3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "|          Date_Time|      Cleaned_Tweets|p_neg|p_neu|p_pos| p_comp|\n",
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "|2021-08-02 04:00:00|The current value...|  0.0|0.876|0.124|   0.34|\n",
            "|2021-08-02 04:00:00|Burger King Start...|  0.0|0.847|0.153| 0.2023|\n",
            "|2021-08-02 04:00:00|DOGE Dogecoin has...|  0.0|0.746|0.254| 0.7003|\n",
            "|2021-08-02 04:00:00|50 Off Olympia US...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2021-08-02 04:00:00|Lezgooow tokyodog...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2021-08-02 04:00:00|Sending 100 Dogec...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2021-08-02 04:00:00|This dude was hyp...|0.086|0.839|0.075| -0.099|\n",
            "|2021-08-02 04:00:00|Destroyer of Shor...|0.231|0.769|  0.0|-0.4588|\n",
            "|2021-08-02 04:00:00|giftsforher bitco...|  0.0|0.884|0.116| 0.4404|\n",
            "|2021-08-02 04:00:00|tumblr twitter fa...|  0.0|0.827|0.173| 0.5574|\n",
            "|2021-08-02 04:00:00|business business...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2021-08-02 04:00:00|linkedin twitter ...|  0.0|0.804|0.196| 0.7269|\n",
            "|2021-08-02 04:00:00|49 Off INFINITIPR...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2021-08-02 04:00:00|People ask me why...|  0.0|0.743|0.257| 0.9217|\n",
            "|2021-08-02 04:00:00|Accept dogecoin d...|  0.0|0.435|0.565| 0.3818|\n",
            "|2021-08-02 04:00:00|Dogecoin DOGE R 1...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2021-08-02 04:00:00|But can I pay in ...|0.242|0.758|  0.0|-0.1531|\n",
            "|2021-08-02 04:00:00|businesstips tips...|  0.0| 0.67| 0.33| 0.6597|\n",
            "|2021-08-02 04:00:00|giftsforher bitco...|  0.0|0.888|0.112| 0.4404|\n",
            "|2021-08-02 04:00:00|linkedin twitter ...|  0.0|0.804|0.196| 0.7269|\n",
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt_truncated = ((round(unix_timestamp(col('Date_Time')) / 3600) * 3600).cast('timestamp'))\n",
        "FinalTw = FinalTw.withColumn('dt_truncated', dt_truncated)\n",
        "FinalTw = FinalTw.selectExpr(\"dt_truncated as Date_Time\",\"Cleaned_Tweets\",\"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "UTC = ((unix_timestamp(col('Date_Time'))+ 5*60*60).cast('timestamp'))\n",
        "FinalTw = FinalTw.withColumn('UTC', UTC)\n",
        "FinalTw = FinalTw.selectExpr(\"UTC as Date_Time\",\"Cleaned_Tweets\",\"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "FinalTw.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaUJPrJgawQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd844e8-1717-48e7-8abe-59b086196fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+------------------+-------------------+-------------------+\n",
            "|           DateTime|              P_Neg|             P_Neu|              P_Pos|             P_Comp|\n",
            "+-------------------+-------------------+------------------+-------------------+-------------------+\n",
            "|2021-08-10 04:00:00|0.02295022629774534|0.8492013599673008|0.11878732993473969|0.22493167258630511|\n",
            "+-------------------+-------------------+------------------+-------------------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw.registerTempTable(\"temp\")\n",
        "FinalTw_avg = sql.sql(\"SELECT Date_Time As DateTime,AVG(p_neg) as P_Neg,AVG(p_neu) as P_Neu,AVG(p_pos) as P_Pos,AVG(p_comp) as P_Comp FROM temp GROUP BY Date_Time\")\n",
        "FinalTw_avg.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhJPX0wNawQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc2f24b-da42-466b-f92e-3e261d88b3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------------------------------+\n",
            "|          Date_Time|concat_ws( , collect_list(Cleaned_Tweets))|\n",
            "+-------------------+------------------------------------------+\n",
            "|2021-08-10 04:00:00|                      The current value...|\n",
            "+-------------------+------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#This cell is just to collect all the corpus per hour(for the future work)\n",
        "from pyspark.sql import functions as f\n",
        "df_with_text = FinalTw.groupby(\"Date_Time\").agg(f.concat_ws(\" \", f.collect_list(FinalTw.Cleaned_Tweets)))\n",
        "df_with_text.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FinalTw_avg.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8lxPrtikwa-",
        "outputId": "53273f85-aa18-4759-e5b6-4be53a28a24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DateTime=datetime.datetime(2021, 8, 10, 4, 0), P_Neg=0.02295022629774534, P_Neu=0.8492013599673008, P_Pos=0.11878732993473969, P_Comp=0.22493167258630511),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 3, 2, 0), P_Neg=0.017873015999794007, P_Neu=0.8612571457075694, P_Pos=0.10182539661015783, P_Comp=0.21920349102408168),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 5, 20, 0), P_Neg=0.02057790377364618, P_Neu=0.8676968865286527, P_Pos=0.11170821464897553, P_Comp=0.2337271936195599),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 7, 14, 0), P_Neg=0.015428270028613288, P_Neu=0.8833291158394472, P_Pos=0.09913291107030106, P_Comp=0.18248755140583725),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 3, 16, 0), P_Neg=0.01714657990911108, P_Neu=0.8412736182977788, P_Pos=0.0959869697568665, P_Comp=0.20514625166497324)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FinalEth.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_XygjUZkwdj",
        "outputId": "dc3be5c3-feb1-4392-f203-df9fd0acce93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DateTime=datetime.datetime(2021, 8, 31, 23, 0), Price='0.27878'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 22, 0), Price='0.27633'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 21, 0), Price='0.27703'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 20, 0), Price='0.27708'),\n",
              " Row(DateTime=datetime.datetime(2021, 8, 31, 19, 0), Price='0.2792')]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-48-i9HawQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8c8116-1b2d-4743-8759-763d10d87d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+-------+\n",
            "|           DateTime|             P_Comp|  Price|\n",
            "+-------------------+-------------------+-------+\n",
            "|2021-08-01 05:00:00|0.22145436779941766|0.21343|\n",
            "|2021-08-01 06:00:00|0.15851342901618196|0.21316|\n",
            "|2021-08-01 07:00:00|0.22179061601852285|0.21247|\n",
            "|2021-08-01 08:00:00|0.17863262226300708|0.21289|\n",
            "|2021-08-01 09:00:00|0.18514932244814186|0.21389|\n",
            "|2021-08-01 10:00:00|0.24531455628008028|0.21134|\n",
            "|2021-08-01 11:00:00| 0.2752749987677494|0.21136|\n",
            "|2021-08-01 12:00:00| 0.2056156067355048|0.21147|\n",
            "|2021-08-01 13:00:00|0.22150343403066555| 0.2105|\n",
            "|2021-08-01 14:00:00| 0.2512646679080532|0.21019|\n",
            "+-------------------+-------------------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw_avg.registerTempTable(\"avgs\")\n",
        "FinalEth.registerTempTable(\"prices\")\n",
        "results = sql.sql(\"SELECT avgs.DateTime, avg(P_Comp) as P_Comp, avg(Price) as Price FROM avgs JOIN prices ON avgs.DateTime = prices.DateTime group by avgs.DateTime order by avgs.DateTime\")\n",
        "results=results.withColumn(\"P_Comp\", lit(results.agg({\"P_Comp\": \"max\"}).collect()[0][0]) - results.P_Comp)\n",
        "results.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXfdxvuTaS2Q",
        "outputId": "0b3b8e91-eee9-45b4-a7fa-de5a80a3dc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+-------+\n",
            "|           DateTime|             P_Comp|  Price|\n",
            "+-------------------+-------------------+-------+\n",
            "|2021-08-01 05:00:00|0.10220562739883218|0.21343|\n",
            "|2021-08-01 06:00:00|0.16514656618206788|0.21316|\n",
            "|2021-08-01 07:00:00|  0.101869379179727|0.21247|\n",
            "|2021-08-01 08:00:00|0.14502737293524276|0.21289|\n",
            "|2021-08-01 09:00:00|0.13851067275010798|0.21389|\n",
            "|2021-08-01 10:00:00|0.07834543891816956|0.21134|\n",
            "|2021-08-01 11:00:00|0.04838499643050043|0.21136|\n",
            "|2021-08-01 12:00:00|0.11804438846274504|0.21147|\n",
            "|2021-08-01 13:00:00|0.10215656116758429| 0.2105|\n",
            "|2021-08-01 14:00:00|0.07239532729019665|0.21019|\n",
            "|2021-08-01 15:00:00|0.09566502714165925|0.21051|\n",
            "|2021-08-01 16:00:00|0.09724580107333158|0.20975|\n",
            "|2021-08-01 17:00:00| 0.1441642690752434|0.20877|\n",
            "|2021-08-01 18:00:00|0.10529089246894113| 0.2094|\n",
            "|2021-08-01 19:00:00|0.08950401681164902|0.21073|\n",
            "|2021-08-01 20:00:00|0.07025749747175725|0.21104|\n",
            "|2021-08-01 21:00:00|0.12462506440030116|0.21033|\n",
            "|2021-08-01 22:00:00|0.12441745683849523|0.20755|\n",
            "|2021-08-01 23:00:00|0.10051447046234421|0.20418|\n",
            "|2021-08-02 00:00:00|0.08846860375208193|0.20329|\n",
            "+-------------------+-------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcOA5WANawQN"
      },
      "outputs": [],
      "source": [
        "#use this csv as the input to the \"ML Model Prediction\" file\n",
        "results.repartition(1).write.csv(\"/content/drive/MyDrive/Big_Data/Final.csv\") #this will write df to single csv instead of writing diff csv acc to partitions "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g_ooUOWRawQH",
        "ieuL-ZWpawQK",
        "4Y06qrGUawQL"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}